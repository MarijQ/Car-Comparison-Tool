# Used Cars Scraper
**Authors:**   Georgios Gkakos, Marij Qureshi, Het Suhagiya

## Websites Permissions

This project respects the robots.txt guidelines for the Carwow, Cargiant and Lookers websites. For details on what is allowed and disallowed for web crawlers, please refer to the robots.txt file included in this project.

This project respects the restrictions set in the robots.txt file by avoiding scraping any disallowed paths or content. The data accessed was strictly for educational purposes, in compliance with ethical scraping practices.

## Table of Contents

1. [Introduction](#introduction)  
2. [Project Overview](#project-overview)   
3. [Scraping and Data Collection](#scraping-and-data-collection)  
4. [Data Storage and Preparation](#data-storage-and-preparation)
5. [Average Price Generation](#average-price-generation) 
6. [User Interface](#user-interface)  
7. [Running the Code](#running-the-code)  
8. [Future Improvements](#future-improvements)  
9. [Team and Contact](#team-and-contact)
10. [License](#license)

---

## Introduction

In this project, we aimed to collect and analyse car listings from three websites: Carwow, Lookers, and Cargiant. Our objective was to build a database capturing key details such as model, make, engine size, and price and provide a reliable average price for the used car market in the UK, useful for both buyers and sellers. We used various technologies to scrape and process the data. Ultimately, we developed an application that allows users to input their car preferences and retrieve the average price from our database.

---

## Project Overview

We utilise a combination of web scraping technologies and database management tools to extract and process data from targeted websites. Our workflow moves from data acquisition through scraping to data storage and user interaction via a custom application.

--- Websites Scraped ---

-  **Carwow** : https://www.carwow.co.uk/used-cars
-  **Lookers** : https://www.lookers.co.uk/used-cars
-  **Cargiant** : https://www.cargiant.co.uk/search/

Each website offers a unique set of data related to used car listings, including details like model, price, engine size, hp, mpg etc.

--- Tech Stack ---

- **Scrapy**:  Orchestrated the web scraping process, data processing and data storage.
- **Selenium**: Helped us interact with dynamic content on the websites.
- **Splash**:  Allowed us to render pages with JavaScript content in a headless browser before scraping.
- **PostgreSQL**:  Used to store and process the scraped data.
- **Python**:  Used to write the scraping scripts, data processing, and dashboard logic.
- **Tkinter**: Utilised to build an application that demonstrates user's interaction with the database  

---

## Scraping and Data Collection
We developed three spiders, each tailored to efficiently scrape data from each website:

**Spiders**
- lookers.py:

  - Tools Used: Utilizes Scrapy for scraping the bulk of car features directly from AJAX API calls, which return data in JSON format.
  - Additional Rendering: Uses Splash to render JavaScript content on the website, enabling the scraping of additional feature lists of cars that are dynamically loaded.

- cargiant.py and carwow.py:

  - Tools Used: Employs Scrapy in conjunction with Selenium. This combination is crucial for handling the complex JavaScript and HTML structures found on these websites, which Splash alone could not adequately process.
  
**Data Standardisation**
- To facilitate the integration of scraped data into a unified database schema, we standardised the extraction of the following features across all three websites:

  -  Basic Car Information: Make, Model, Year, Price, Mileage
  -  Specifications: Fuel Type, Body Style, Engine Size, Horsepower (hp)
  -  Transmission Details: Type of Transmission
  -  Dealership Data: Name of the Dealership
  -  Efficiency and Capacity: Miles Per Gallon (mpg), Number of Doors
  -  Ownership History: Number of Previous Owners
  -  Additional Details: Droplet, List of Additional Features

---

## Data Storage and Preparation
The scraped data is processed and stored in a **PostgreSQL** database.

**Table's Structure and Description:**
| Column Name      | Data Type      | Description                                   |
|------------------|----------------|-----------------------------------------------|
| id               | SERIAL         | Primary key, auto-increments with each entry  |
| make             | VARCHAR(100)   | Brand of the car                              |
| model            | VARCHAR(100)   | Model of the car                              |
| price            | NUMERIC        | Sale price of the car                         |
| mileage          | NUMERIC        | Total miles driven by the car                 |
| fuel_type        | VARCHAR(50)    | Type of fuel used (e.g., Diesel, Petrol)      |
| body_style       | VARCHAR(100)   | Style of the car body (e.g., Sedan, SUV)      |
| engine_size      | VARCHAR(50)    | Engine size (e.g., 2.0L)                      |
| hp               | VARCHAR(50)    | Horsepower of the car                         |
| transmission     | VARCHAR(50)    | Type of transmission (e.g., Manual, Automatic)|
| year             | INT            | Year of manufacture                           |
| dealership_name  | VARCHAR(255)   | Name of the dealership selling the car        |
| mpg              | VARCHAR(50)    | Miles per gallon                              |
| n_doors          | VARCHAR(50)    | Number of doors                               |
| previous_owners  | VARCHAR(50)    | Number of previous owners                     |
| droplet          | VARCHAR(50)    | Colour of the car                             |
| feature_list     | TEXT           | List of additional features                   |
| last_updated     | TIMESTAMP      | Timestamp of the last update to the record    |

**Handling Missing Values**
- Any missing values in the dataset were retained as is for the current implementation. Future updates may address these through appropriate imputation techniques to ensure comprehensive data analysis
  
**Database Interaction with Psycopg2**
- We utilise the psycopg2 library to execute SQL-like queries directly from Python. When calculating the average price of cars, our queries are designed to consider only those car listings that fall within one standard deviation from the user-inputted value for each numeric attribute. For textual attributes, the matches must be exact.

---

## Average Price Generation
Calculation Methodology
- Only listings that meet these specified criteria are included in the calculations of the average price. Both the standard deviation and average price functions in psycopg2 inherently exclude rows with missing values in the relevant columns, ensuring that our statistics are computed based on complete and relevant data only.

---

## User Interface



---

## Running the code
explain how to run the code, dependencies and requirements, file/directory structure
ADD versions used 
ADD commands for how to run the code
ADD how the user can use tkinter

---

## Future Improvements
- Recommendation system
- competitor analysis
- car comparision based on the user inputs
- Car Depreciation Prediction based on the car age, its original price, current price and the no. of owners
- Web-Scraping: Add more sites like AutoTrader; improve anti-bot techniques.
- Web-Scraping: Handle CAPTCHA and use proxy rotation for dynamic scraping.
- ETL: Automate missing data handling; clean inconsistent records.
- ETL: Schedule real-time scraping for fresh data syncs (daily scheduled scrape).
- Analytics: Build ML models to predict car prices using features.
- Analytics: Analyze multi-year trends for pricing and popular models.
- UI: Upgrade GUI to modern web app with Flask or React.
- UI: Add intelligent filters based on user preferences (e.g. combinations of filters)
- NLP: Analyze seller descriptions for tone, sentiment, or key details.
- ⁠Integrate an ML model that can handle missing values on the explanatory features and calculates the average price
- ⁠Create a web application that provides a more attractive UI to the user to use.
- ⁠Run all the scrapers in parallel on a distributed system (such as spark) to enhance the runtime.
- ⁠Incorporate new websites to the database to make the calculation of the average price more representative of the current market.
- ⁠Group the calculations of the average price by location to account for spatial variation in prices of used cars in the UK.
- ⁠Add a tool that will calculate the insurance cost based on the generated average price among with other inputs (such as age of the user)
- ⁠Enhance the runtime of the scrapers that have to load different pages to collect the data using VPN (parallelizing the process)
- ⁠How a difference in features might impact the price (for example a car having a 20mpg less than the other) through a linear model (after handling missing values)

---

## Team and Contact

- **Marij**: MEng Aeronautical (Imperial), MSc Data Science (Brunel), ex-EY Parthenon
- **Het**: MSc Data Science (Brunel), BSc Information Technology 
- **George**: MSc Data Science (Brunel), BSc Economics (AUTH)

For questions, feel free to reach out via GitHub issues or email any of us.

---

## License
This project is licensed under the MIT License. See the [LICENSE](License) file for more details.

---
